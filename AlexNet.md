
# AlexNet 
---
`省略了FC的偏差项计算`

| Layer | Input Size| Output Size | Parameters | Forward Computation |
|---|---|---|---|---|
|**Conv1**|3 * 227 * 227|96 * 55 * 55|`(11 * 11 * 3 + 1) * 96=34944`|34944 * 55 * 55|
|Max Pooling|96 * 55 * 55|96 * 27 * 27| 0 | 0 |
|**Conv2**|96 * 27 * 27| 256 * 27 * 27|`(5 * 5 * 96 + 1) * 256=614656`|614656 * 27 * 27|
|Max Pooling|256 * 27 * 27|256 * 13 * 13| 0 | 0 |
|**Conv3**|256 * 13 * 13|384 * 13 * 13|`(3 * 3 * 256 + 1) * 384=885120`|885120 * 13 * 13|
|**Conv4**|384 * 13 * 13|384 * 13 * 13|`(3 * 3 * 384 + 1) * 384=1327488`|1327488 * 13 * 13|
|**Conv5**|384 * 13 * 13|256 * 13 * 13|`(3 * 3 * 384 + 1) * 256=884992`|884992 * 13 * 13|
|Max Pooling|256 * 13 * 13|256 * 6 * 6| 0 | 0 |
|**FC6**|1 * 9216|1 * 4096|`256 * 6 * 6 * 4096=37748736`|37748736|
|**FC7**|1 * 4096|1 * 4096|`4096 * 4096=16777216`|16777216|
|**FC**|1 * 4096|1 * 1000|`4096 * 1000=4096000`|4096000|

## 防止过拟合
---
### Dropout
- 使用dropout而不是正则化来处理过度拟合，同时训练时间加倍。
- 在训练期间，每个神经元都有可能不参与前馈传递并参与反向传播。因此，每个神经元都有更大的机会被训练，而不是非常依赖于一些非常“强壮”的神经元。

### Data Augmentation
#### First :  `Image translation and horizontal reflection`
#### Second:  ` Altering the intensity`
- 通过增加数据增加训练集的大小，Top-1错误率降低了1％以上。
- 增强model泛化性。
